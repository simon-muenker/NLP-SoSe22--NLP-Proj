> Loaded logger: ./experiments/_debug/transformer/full.log
> Setup PyTorch: seed(1), cuda(5)

[--- PREPARE DATA -> (['train', 'eval', 'test']) ---]
> Load/Init from ./data/imdb._debug.csv
> f(__load) took: 0.0032 sec
> Load/Init from ./data/imdb._debug.csv
> f(__load) took: 0.0017 sec
> Load/Init from ./data/imdb._debug.csv
> f(__load) took: 0.0016 sec

[--- LOAD COMPONENTS ---]
> Init Encoder: 'fabriceyhc/bert-base-uncased-imdb'
Lock 140065460820336 acquired on /home/muenker/.cache/huggingface/transformers/302ed971b61e0e1588713b681f54356f9b2d311e4e583a926bc35a2b3722a368.59407384618422b5f582b6046df91db98a0f921d6c959dc7b1f50000ffea1032.lock
Lock 140065460820336 released on /home/muenker/.cache/huggingface/transformers/302ed971b61e0e1588713b681f54356f9b2d311e4e583a926bc35a2b3722a368.59407384618422b5f582b6046df91db98a0f921d6c959dc7b1f50000ffea1032.lock
Lock 140065231698384 acquired on /home/muenker/.cache/huggingface/transformers/451f0b6ce35a7f7c5d785a8126ef7cc6ad60da33b383beed5bad35c32404a87d.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock
Lock 140065231698384 released on /home/muenker/.cache/huggingface/transformers/451f0b6ce35a7f7c5d785a8126ef7cc6ad60da33b383beed5bad35c32404a87d.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock
Lock 140065231697856 acquired on /home/muenker/.cache/huggingface/transformers/72c1261aa6165ade37c9a5da47883d56706fc41b34103836e5ffdbdbf5a21dbe.919dfe2fb70c7d2dadad899bb11d0ab6c5f308d9616c3e5230ffd6fde6c7df84.lock
Lock 140065231697856 released on /home/muenker/.cache/huggingface/transformers/72c1261aa6165ade37c9a5da47883d56706fc41b34103836e5ffdbdbf5a21dbe.919dfe2fb70c7d2dadad899bb11d0ab6c5f308d9616c3e5230ffd6fde6c7df84.lock
Lock 140065231357792 acquired on /home/muenker/.cache/huggingface/transformers/e60863a75b1372ac7dc58399e55b9912c2335f9e52382dea26a715521a12863c.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d.lock
Lock 140065231357792 released on /home/muenker/.cache/huggingface/transformers/e60863a75b1372ac7dc58399e55b9912c2335f9e52382dea26a715521a12863c.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d.lock
Lock 140065231699920 acquired on /home/muenker/.cache/huggingface/transformers/bd62d309ee822caf3777ed4c3e0beea7c486a51e5a4dc929880a5d6a77837a58.994b1d248aee02666808e61dc5ffd7c6093e426f41a3c9d67bf5e301690077b2.lock
Lock 140065231699920 released on /home/muenker/.cache/huggingface/transformers/bd62d309ee822caf3777ed4c3e0beea7c486a51e5a4dc929880a5d6a77837a58.994b1d248aee02666808e61dc5ffd7c6093e426f41a3c9d67bf5e301690077b2.lock
Lock 140065461334848 acquired on /home/muenker/.cache/huggingface/transformers/d74b833be0d9a5d3c805bd51062dc1becb7c8ba5703ecad7a5c8e1a464197198.38772bd2021b1c1f49aa9cca04046acd05977dba4ff783d262c3a85ed0403899.lock
Lock 140065461334848 released on /home/muenker/.cache/huggingface/transformers/d74b833be0d9a5d3c805bd51062dc1becb7c8ba5703ecad7a5c8e1a464197198.38772bd2021b1c1f49aa9cca04046acd05977dba4ff783d262c3a85ed0403899.lock
> f(__init__) took: 23.2767 sec
> Init BERT-Head (MLP), trainable parameters: 197378

[--- TRAIN -> ./data/imdb._debug.csv ---]
@001: 	loss(train)=0.6879 	loss(eval)=0.4685 	f1(train)=0.2500 	f1(eval)=0.9750 	duration(epoch)=0:00:01.075667
@002: 	loss(train)=0.3832 	loss(eval)=0.2604 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.021735
@003: 	loss(train)=0.2127 	loss(eval)=0.1461 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.016996
@004: 	loss(train)=0.1270 	loss(eval)=0.1034 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.003887
@005: 	loss(train)=0.1501 	loss(eval)=0.0668 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.013226
@006: 	loss(train)=0.0731 	loss(eval)=0.0533 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.015614
@007: 	loss(train)=0.0458 	loss(eval)=0.0420 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.023603
@008: 	loss(train)=0.0450 	loss(eval)=0.0391 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.025714
@009: 	loss(train)=0.0343 	loss(eval)=0.0360 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.007254
@010: 	loss(train)=0.0363 	loss(eval)=0.0317 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.018377
@011: 	loss(train)=0.0290 	loss(eval)=0.0953 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.027416
@012: 	loss(train)=0.0337 	loss(eval)=0.0288 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.009793
@013: 	loss(train)=0.0325 	loss(eval)=0.0297 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.026435
@014: 	loss(train)=0.0305 	loss(eval)=0.0237 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.015857
@015: 	loss(train)=0.0263 	loss(eval)=0.0216 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.009226
@016: 	loss(train)=0.0213 	loss(eval)=0.0198 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.012800
@017: 	loss(train)=0.0699 	loss(eval)=0.0620 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.017421
@018: 	loss(train)=0.0222 	loss(eval)=0.0183 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.028497
@019: 	loss(train)=0.0183 	loss(eval)=0.0164 	f1(train)=0.9750 	f1(eval)=0.9750 	duration(epoch)=0:00:01.023817
@020: 	loss(train)=0.0153 	loss(eval)=0.0442 	f1(train)=0.9750 	f1(eval)=1.0000 	duration(epoch)=0:00:01.018260
@021: 	loss(train)=0.0149 	loss(eval)=0.0130 	f1(train)=1.0000 	f1(eval)=1.0000 	duration(epoch)=0:00:01.008273
@022: 	loss(train)=0.0334 	loss(eval)=0.0144 	f1(train)=1.0000 	f1(eval)=1.0000 	duration(epoch)=0:00:01.017406
@023: 	loss(train)=0.0134 	loss(eval)=0.0342 	f1(train)=1.0000 	f1(eval)=1.0000 	duration(epoch)=0:00:01.008492
@024: 	loss(train)=0.0119 	loss(eval)=0.0122 	f1(train)=1.0000 	f1(eval)=1.0000 	duration(epoch)=0:00:01.019352
@025: 	loss(train)=0.0134 	loss(eval)=0.0103 	f1(train)=1.0000 	f1(eval)=1.0000 	duration(epoch)=0:00:01.019456
> Load best model based on evaluation loss.
> Init BERT-Head (MLP), trainable parameters: 197378
@025: 	loss(train)=0.0134 	loss(eval)=0.0103 	f1(train)=1.0000 	f1(eval)=1.0000 	duration(epoch)=0:00:01.019456

[--- EVAL -> ./data/imdb._debug.csv ---]
AVG           	 tp:       40	 fp:        0 	 tn:       40	 fn:        0	 pre=1.0000	 rec=1.0000	 f1=1.0000	 acc=1.0000
negative      	 tp:       27	 fp:        0 	 tn:       13	 fn:        0	 pre=1.0000	 rec=1.0000	 f1=1.0000	 acc=1.0000
positive      	 tp:       13	 fp:        0 	 tn:       27	 fn:        0	 pre=1.0000	 rec=1.0000	 f1=1.0000	 acc=1.0000
