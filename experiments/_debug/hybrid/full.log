> Loaded logger: ./experiments/_debug/hybrid/full.log
> Setup PyTorch: seed(1), cuda(5)

[--- PREPARE DATA -> (['train', 'eval']) ---]
> f(__load) took: 0.0038 sec
> Load/Init from ./data/imdb._debug.csv
  Number of Samples: 40 
  Memory Usage: 0.0729 MB
> f(__tokenize) took: 0.2586 sec
> f(__ngram) took: 0.2217 sec
> f(__ngram) took: 0.2282 sec
> f(__load) took: 0.0048 sec
> Load/Init from ./data/imdb._debug.csv
  Number of Samples: 40 
  Memory Usage: 0.0729 MB
> f(__tokenize) took: 0.2453 sec
> f(__ngram) took: 0.2390 sec
> f(__ngram) took: 0.3267 sec

[--- LOAD COMPONENTS ---]
> Init Encoder: 'bert-base-uncased'
  Memory Usage: 417.6494 MB
> f(__init__) took: 9.4837 sec
> f(df_encode) took: 0.5429 sec
> Memory Usage (w/ Embeds): 0.2730 MB
> f(df_encode) took: 0.5114 sec
> Memory Usage (w/ Embeds): 0.2730 MB

[--- FEATURE PIPELINE ---]
> Fit Pipeline ./data/imdb._debug.csv on (only N-Gram Group Counter)
> f(fit) took: 0.0000 sec
> Apply Feature Pipeline on ./data/imdb._debug.csv
> f(apply) took: 0.0000 sec
> Apply Feature Pipeline on ./data/imdb._debug.csv
> f(apply) took: 0.0001 sec
> f(df_encode) took: 0.9316 sec
> f(match) took: 0.0290 sec
> f(match) took: 0.0280 sec
> Init Base+Features+MetaMatcher Concatenation (Hybrid)
  Memory Usage: 0.0117 MB
  Trainable parameters: 3074
  Input Dimension: 1536
  Output Dimension: 2

[--- TRAIN -> ./data/imdb._debug.csv ---]
@005: 	loss(train)=0.5896 	loss(eval)=0.5630 	f1(train)=0.6750 	f1(eval)=0.6750 	duration(epoch)=0:00:00.032609
@010: 	loss(train)=0.5025 	loss(eval)=0.5972 	f1(train)=0.6750 	f1(eval)=0.6750 	duration(epoch)=0:00:00.032347
@015: 	loss(train)=0.5192 	loss(eval)=0.4991 	f1(train)=0.7000 	f1(eval)=0.7000 	duration(epoch)=0:00:00.032485
@020: 	loss(train)=0.4160 	loss(eval)=0.5053 	f1(train)=0.7500 	f1(eval)=0.7750 	duration(epoch)=0:00:00.032016
@025: 	loss(train)=0.5141 	loss(eval)=0.4435 	f1(train)=0.7250 	f1(eval)=0.7250 	duration(epoch)=0:00:00.031921
@030: 	loss(train)=0.4565 	loss(eval)=0.4520 	f1(train)=0.7500 	f1(eval)=0.7500 	duration(epoch)=0:00:00.031866
@035: 	loss(train)=0.4024 	loss(eval)=0.4924 	f1(train)=0.7500 	f1(eval)=0.7500 	duration(epoch)=0:00:00.031775
@040: 	loss(train)=0.3999 	loss(eval)=0.4304 	f1(train)=0.7500 	f1(eval)=0.7750 	duration(epoch)=0:00:00.031947
@045: 	loss(train)=0.4067 	loss(eval)=0.4347 	f1(train)=0.7500 	f1(eval)=0.8000 	duration(epoch)=0:00:00.031964
@050: 	loss(train)=0.4567 	loss(eval)=0.3266 	f1(train)=0.7250 	f1(eval)=0.7500 	duration(epoch)=0:00:00.031883
@055: 	loss(train)=0.3845 	loss(eval)=0.2954 	f1(train)=0.8250 	f1(eval)=0.8000 	duration(epoch)=0:00:00.031873
@060: 	loss(train)=0.3643 	loss(eval)=0.3108 	f1(train)=0.8250 	f1(eval)=0.7750 	duration(epoch)=0:00:00.031869
@065: 	loss(train)=0.3735 	loss(eval)=0.3020 	f1(train)=0.7750 	f1(eval)=0.8500 	duration(epoch)=0:00:00.031984
@070: 	loss(train)=0.3173 	loss(eval)=0.3393 	f1(train)=0.8500 	f1(eval)=0.8500 	duration(epoch)=0:00:00.032159
@075: 	loss(train)=0.3458 	loss(eval)=0.3501 	f1(train)=0.8250 	f1(eval)=0.7750 	duration(epoch)=0:00:00.031906
@080: 	loss(train)=0.2888 	loss(eval)=0.3197 	f1(train)=0.9000 	f1(eval)=0.8500 	duration(epoch)=0:00:00.032085
@085: 	loss(train)=0.2858 	loss(eval)=0.3022 	f1(train)=0.8500 	f1(eval)=0.8500 	duration(epoch)=0:00:00.032149
@090: 	loss(train)=0.2733 	loss(eval)=0.3268 	f1(train)=0.9000 	f1(eval)=0.8250 	duration(epoch)=0:00:00.031888
@095: 	loss(train)=0.2898 	loss(eval)=0.2722 	f1(train)=0.8750 	f1(eval)=0.8500 	duration(epoch)=0:00:00.032054
@100: 	loss(train)=0.2929 	loss(eval)=0.4137 	f1(train)=0.8250 	f1(eval)=0.8250 	duration(epoch)=0:00:00.031975
> Load best model based on evaluation loss.
> Init Base+Features+MetaMatcher Concatenation (Hybrid)
  Memory Usage: 0.0117 MB
  Trainable parameters: 3074
  Input Dimension: 1536
  Output Dimension: 2
@097: 	loss(train)=0.3106 	loss(eval)=0.3110 	f1(train)=0.8500 	f1(eval)=0.8500 	duration(epoch)=0:00:00.031643

[--- EVAL -> ./data/imdb._debug.csv ---]
AVG           	 tp:       34	 fp:        6 	 tn:       34	 fn:        6	 pre=0.8500	 rec=0.8500	 f1=0.8500	 acc=0.8500
negative      	 tp:       27	 fp:        6 	 tn:        7	 fn:        0	 pre=0.8182	 rec=1.0000	 f1=0.9000	 acc=0.8500
positive      	 tp:        7	 fp:        0 	 tn:       27	 fn:        6	 pre=1.0000	 rec=0.5385	 f1=0.7000	 acc=0.8500
