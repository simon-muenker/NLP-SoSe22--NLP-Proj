> Loaded logger: ./experiments/hybrid/full.log
> Setup PyTorch: seed(1), cuda(5)

[--- PREPARE DATA -> (['train', 'eval']) ---]
> Load/Init from ./data/imdb.train.csv
> f(__load) took: 0.2831 sec
> f(__tokenize) took: 4.5587 sec
> f(__ngram) took: 1.5986 sec
> f(__ngram) took: 1.7971 sec
> Load/Init from ./data/imdb.eval.csv
> f(__load) took: 0.0346 sec
> f(__tokenize) took: 1.1047 sec
> f(__ngram) took: 0.7603 sec
> f(__ngram) took: 0.7952 sec

[--- LOAD COMPONENTS ---]
> Init Encoder: 'fabriceyhc/bert-base-uncased-imdb'
> f(__init__) took: 8.4418 sec

[--- FEATURE PIPELINE ---]
> Init N-Gram Group Counter, with: [('1', 768), ('2', 5120)]
> Init NELA Pipeline
> Fit Pipeline ./data/imdb.train.csv on (only N-Gram Group Counter)
> f(fit) took: 3.6442 sec
> Apply Feature Pipeline on ./data/imdb.train.csv
> f(apply) took: 227.4208 sec
> Apply Feature Pipeline on ./data/imdb.eval.csv
> f(apply) took: 30.8731 sec
> Init BERT-Head (Base), trainable parameters: 1538
> Init Neural Weighting (Feature), trainable parameters: 184
> Init Neural Assemble (Base+Features), trainable parameters: 10

[--- TRAIN -> ./data/imdb.train.csv ---]
@001: 	loss(train)=0.4024 	loss(eval)=0.2922 	f1(train)=0.8278 	f1(eval)=0.9266 	duration(epoch)=0:05:55.276054
@002: 	loss(train)=0.3102 	loss(eval)=0.2821 	f1(train)=0.8610 	f1(eval)=0.9270 	duration(epoch)=0:05:58.554850
@003: 	loss(train)=0.2626 	loss(eval)=0.2571 	f1(train)=0.8661 	f1(eval)=0.9262 	duration(epoch)=0:05:57.996361
@004: 	loss(train)=0.2450 	loss(eval)=0.2272 	f1(train)=0.8636 	f1(eval)=0.9270 	duration(epoch)=0:05:57.725318
@005: 	loss(train)=0.2337 	loss(eval)=0.2175 	f1(train)=0.8616 	f1(eval)=0.9274 	duration(epoch)=0:05:57.553143
> Load best model based on evaluation loss.
> Init BERT-Head (Base), trainable parameters: 1538
> Init Neural Weighting (Feature), trainable parameters: 184
> Init Neural Assemble (Base+Features), trainable parameters: 10
@005: 	loss(train)=0.2337 	loss(eval)=0.2175 	f1(train)=0.8616 	f1(eval)=0.9274 	duration(epoch)=0:05:57.553143

[--- EVAL -> ./data/imdb.eval.csv ---]
AVG           	 tp:     2301	 fp:      180 	 tn:     2301	 fn:      180	 pre=0.9274	 rec=0.9274	 f1=0.9274	 acc=0.9274
negative      	 tp:     1100	 fp:       79 	 tn:     1201	 fn:      101	 pre=0.9330	 rec=0.9159	 f1=0.9244	 acc=0.9274
positive      	 tp:     1201	 fp:      101 	 tn:     1100	 fn:       79	 pre=0.9224	 rec=0.9383	 f1=0.9303	 acc=0.9274
