> Loaded logger: ./experiments/hybrid/full.log
> Setup PyTorch: seed(1), cuda(5)

[--- PREPARE DATA -> (['train', 'eval', 'test']) ---]
> Load/Init from ./data/imdb.train.csv
> f(__load) took: 0.4210 sec
> f(__tokenize) took: 6.2059 sec
> f(__ngram) took: 2.6754 sec
> f(__ngram) took: 2.5935 sec
> Load/Init from ./data/imdb.eval.csv
> f(__load) took: 0.0579 sec
> f(__tokenize) took: 1.6264 sec
> f(__ngram) took: 3.9586 sec
> f(__ngram) took: 1.0182 sec
> Load/Init from ./data/imdb.test.csv
> f(__load) took: 0.0588 sec
> f(__tokenize) took: 1.6998 sec
> f(__ngram) took: 1.0702 sec
> f(__ngram) took: 1.1555 sec

[--- LOAD COMPONENTS ---]
> Init Encoder: 'fabriceyhc/bert-base-uncased-imdb'
> f(__init__) took: 8.5583 sec

[--- FEATURE PIPELINE ---]
> Init Freq. Classifier, n-grams: ['1', '2']
> Fit Freq. Classifier on ./data/imdb.train.csv
> f(fit) took: 5.4311 sec
> Predict with Freq. Classifier on ./data/imdb.train.csv
> f(apply) took: 15.1713 sec
> Predict with Freq. Classifier on ./data/imdb.eval.csv
> f(apply) took: 7.5079 sec
> Predict with Freq. Classifier on ./data/imdb.test.csv
> f(apply) took: 7.4264 sec
> Init BERT-Head (Base), trainable parameters: 197378
> Init Neural Weighting (Feature), trainable parameters: 8
> Init Neural Assemble (Base+Features), trainable parameters: 8

[--- TRAIN -> ./data/imdb.train.csv ---]
@001: 	loss(train)=0.1449 	loss(eval)=0.1349 	f1(train)=0.9570 	f1(eval)=0.9566 	duration(epoch)=0:09:42.393403
@002: 	loss(train)=0.1658 	loss(eval)=0.1533 	f1(train)=0.9578 	f1(eval)=0.9578 	duration(epoch)=0:09:44.233392
@003: 	loss(train)=0.1774 	loss(eval)=0.1811 	f1(train)=0.9592 	f1(eval)=0.9576 	duration(epoch)=0:09:42.506798
@004: 	loss(train)=0.1783 	loss(eval)=0.1794 	f1(train)=0.9593 	f1(eval)=0.9582 	duration(epoch)=0:09:43.341789
@005: 	loss(train)=0.1813 	loss(eval)=0.1605 	f1(train)=0.9595 	f1(eval)=0.9576 	duration(epoch)=0:09:42.117382
> Load best model based on evaluation loss.
> Init BERT-Head (Base), trainable parameters: 197378
> Init Neural Weighting (Feature), trainable parameters: 8
> Init Neural Assemble (Base+Features), trainable parameters: 8
@004: 	loss(train)=0.1783 	loss(eval)=0.1794 	f1(train)=0.9593 	f1(eval)=0.9582 	duration(epoch)=0:09:43.341789

[--- EVAL -> ./data/imdb.eval.csv ---]
AVG           	 tp:     4751	 fp:      207 	 tn:     4751	 fn:      207	 pre=0.9582	 rec=0.9582	 f1=0.9582	 acc=0.9582
negative      	 tp:     2336	 fp:      113 	 tn:     2415	 fn:       94	 pre=0.9539	 rec=0.9613	 f1=0.9576	 acc=0.9582
positive      	 tp:     2415	 fp:       94 	 tn:     2336	 fn:      113	 pre=0.9625	 rec=0.9553	 f1=0.9589	 acc=0.9582
