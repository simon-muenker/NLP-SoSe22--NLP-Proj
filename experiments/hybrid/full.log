> Loaded logger: ./experiments/hybrid/full.log
> Setup PyTorch: seed(1), cuda(5)

[--- PREPARE DATA -> (['train', 'eval']) ---]
> Load/Init from ./data/imdb.train.csv
> f(__load) took: 0.2771 sec
> f(__tokenize) took: 4.6155 sec
> f(__ngram) took: 1.5915 sec
> f(__ngram) took: 1.8093 sec
> Load/Init from ./data/imdb.eval.csv
> f(__load) took: 0.0348 sec
> f(__tokenize) took: 1.1175 sec
> f(__ngram) took: 0.7643 sec
> f(__ngram) took: 0.8089 sec

[--- LOAD COMPONENTS ---]
> Init Encoder: 'fabriceyhc/bert-base-uncased-imdb'
> f(__init__) took: 8.6691 sec

[--- FEATURE PIPELINE ---]
> Init N-Gram Group Counter, with: [('1', 768), ('2', 5120)]
> Init NELA Pipeline
> Fit Pipeline ./data/imdb.train.csv on (only N-Gram Group Counter)
> f(fit) took: 3.8988 sec
> Apply Feature Pipeline on ./data/imdb.train.csv
> f(apply) took: 112.1294 sec
> Apply Feature Pipeline on ./data/imdb.eval.csv
> f(apply) took: 18.2655 sec
> Init BERT-Head (Base), trainable parameters: 1538
> Init Neural Weighting (Feature), trainable parameters: 66
> Init Neural Assemble (Base+Features), trainable parameters: 10

[--- TRAIN -> ./data/imdb.train.csv ---]
@001: 	loss(train)=0.0978 	loss(eval)=0.2847 	f1(train)=0.9608 	f1(eval)=0.9323 	duration(epoch)=0:06:04.465400
@002: 	loss(train)=0.0684 	loss(eval)=0.2388 	f1(train)=0.9810 	f1(eval)=0.9307 	duration(epoch)=0:06:06.165074
@003: 	loss(train)=0.0670 	loss(eval)=0.2723 	f1(train)=0.9804 	f1(eval)=0.9331 	duration(epoch)=0:06:07.480514
@004: 	loss(train)=0.0677 	loss(eval)=0.2701 	f1(train)=0.9806 	f1(eval)=0.9327 	duration(epoch)=0:06:07.229211
@005: 	loss(train)=0.0693 	loss(eval)=0.2689 	f1(train)=0.9810 	f1(eval)=0.9323 	duration(epoch)=0:06:07.487095
@006: 	loss(train)=0.0673 	loss(eval)=0.2315 	f1(train)=0.9815 	f1(eval)=0.9323 	duration(epoch)=0:06:05.677104
@007: 	loss(train)=0.0679 	loss(eval)=0.2832 	f1(train)=0.9806 	f1(eval)=0.9327 	duration(epoch)=0:06:06.474329
@008: 	loss(train)=0.0639 	loss(eval)=0.3360 	f1(train)=0.9811 	f1(eval)=0.9327 	duration(epoch)=0:06:05.350174
@009: 	loss(train)=0.0702 	loss(eval)=0.2699 	f1(train)=0.9803 	f1(eval)=0.9319 	duration(epoch)=0:06:06.450546
@010: 	loss(train)=0.0633 	loss(eval)=0.2548 	f1(train)=0.9817 	f1(eval)=0.9315 	duration(epoch)=0:06:07.230245
@011: 	loss(train)=0.0638 	loss(eval)=0.2857 	f1(train)=0.9822 	f1(eval)=0.9335 	duration(epoch)=0:06:06.332726
@012: 	loss(train)=0.0616 	loss(eval)=0.2536 	f1(train)=0.9835 	f1(eval)=0.9323 	duration(epoch)=0:06:05.812532
@013: 	loss(train)=0.0596 	loss(eval)=0.2259 	f1(train)=0.9825 	f1(eval)=0.9315 	duration(epoch)=0:06:06.488747
@014: 	loss(train)=0.0591 	loss(eval)=0.2629 	f1(train)=0.9830 	f1(eval)=0.9307 	duration(epoch)=0:06:06.322595
@015: 	loss(train)=0.0593 	loss(eval)=0.2728 	f1(train)=0.9840 	f1(eval)=0.9315 	duration(epoch)=0:06:05.993562
@016: 	loss(train)=0.0583 	loss(eval)=0.2635 	f1(train)=0.9842 	f1(eval)=0.9315 	duration(epoch)=0:06:06.804971
@017: 	loss(train)=0.0572 	loss(eval)=0.2963 	f1(train)=0.9840 	f1(eval)=0.9327 	duration(epoch)=0:06:05.999441
@018: 	loss(train)=0.0557 	loss(eval)=0.2486 	f1(train)=0.9842 	f1(eval)=0.9327 	duration(epoch)=0:06:07.065875
@019: 	loss(train)=0.0576 	loss(eval)=0.2826 	f1(train)=0.9833 	f1(eval)=0.9347 	duration(epoch)=0:06:06.157057
@020: 	loss(train)=0.0566 	loss(eval)=0.3067 	f1(train)=0.9844 	f1(eval)=0.9339 	duration(epoch)=0:06:06.044805
> Load best model based on evaluation loss.
> Init BERT-Head (Base), trainable parameters: 1538
> Init Neural Weighting (Feature), trainable parameters: 66
> Init Neural Assemble (Base+Features), trainable parameters: 10
@019: 	loss(train)=0.0576 	loss(eval)=0.2826 	f1(train)=0.9833 	f1(eval)=0.9347 	duration(epoch)=0:06:06.157057

[--- EVAL -> ./data/imdb.eval.csv ---]
AVG           	 tp:     2319	 fp:      162 	 tn:     2319	 fn:      162	 pre=0.9347	 rec=0.9347	 f1=0.9347	 acc=0.9347
negative      	 tp:     1125	 fp:       86 	 tn:     1194	 fn:       76	 pre=0.9290	 rec=0.9367	 f1=0.9328	 acc=0.9347
positive      	 tp:     1194	 fp:       76 	 tn:     1125	 fn:       86	 pre=0.9402	 rec=0.9328	 f1=0.9365	 acc=0.9347
